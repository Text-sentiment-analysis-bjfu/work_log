{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "text = (open(\"sonnets.txt\").read())\n",
    "text=text.lower()\n",
    "print(sorted(list(set(text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating character/word mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 20, 0, 0, 1, 17, 29, 26, 24, 1, 17, 12, 20, 29, 16, 30, 31, 1, 14, 29, 16, 12, 31, 32, 29, 16, 30, 1, 34, 16, 1, 15, 16, 30, 20, 29, 16, 1, 20, 25, 14, 29, 16, 12, 30, 16, 6, 0, 1, 31, 19, 12, 31, 1, 31, 19, 16, 29, 16, 13, 36, 1, 13, 16, 12, 32, 31, 36, 3, 30, 1, 29, 26, 30, 16, 1, 24, 20, 18, 19, 31, 1, 25, 16, 33, 16, 29, 1, 15, 20, 16, 6, 0, 1, 13, 32, 31, 1, 12, 30]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)\n",
    "print(Y_modified[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "97820/97820 [==============================] - 12269s 125ms/step - loss: 2.8514\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)\n",
    "\n",
    "model.save_weights('/Users/pranjal/Desktop/text_generator/models/text_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/Users/pranjal/Desktop/text_generator/models/text_generator_400_0.2_400_0.2_baseline.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s the riper should by time decease,\\n his tender heir might bear his memory:\\n but thou, contracted toet she the the the the the the the the \\n      thi the the the the the the the the the the the the the the the the the \\n      thi the the the the the the the the the the the the the the the the the \\n      thi the the the the the the the the the the the the the the the the the \\n      thi the the the the the the the the the the the the the the the the the \\n      thi the the the the the the the the th'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
